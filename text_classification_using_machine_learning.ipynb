{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> CSCI 6515 - Assignment - B00825788 <center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "msrZbtaz16D1"
   },
   "outputs": [],
   "source": [
    "#importing all the required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qttNxmdS16D9"
   },
   "source": [
    "# Question 1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z6CkR9T516D_"
   },
   "outputs": [],
   "source": [
    "#extracting zip files\n",
    "\n",
    "def extractZipFiles():\n",
    "    rootdir = './Data/'\n",
    "    for file in os.listdir(rootdir):   \n",
    "        if(file.endswith(\".zip\")):\n",
    "            with ZipFile(os.path.join('./Data/', file), 'r') as zip: \n",
    "                zip.extractall('./extracted_files/')\n",
    "\n",
    "extractZipFiles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JGBnpHIN16EE"
   },
   "source": [
    "# Question 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mp9ib6bP16EF"
   },
   "outputs": [],
   "source": [
    "# loading the dataframe with content extracted from xml files\n",
    "\n",
    "def loadDataFrame():\n",
    "    df = pd.DataFrame(columns=['Headline','Text','bip:topics','dc.date.published','itemid','XMLfilename'])\n",
    "    unique_bip_topics = set()\n",
    "\n",
    "    rootdir = './extracted_files/'\n",
    "    for file in os.listdir(rootdir):\n",
    "        fileName = file\n",
    "        if(file.endswith(\".xml\")):\n",
    "            file = open(os.path.join('./extracted_files/', file)).read()        \n",
    "            file_contents = BeautifulSoup(file)\n",
    "            headline = file_contents.headline.text\n",
    "            text = file_contents.findAll(\"text\")[0].text\n",
    "            itemId = file_contents.newsitem[\"itemid\"]        \n",
    "            dc_date_published = file_contents.findAll(attrs={\"element\" : \"dc.date.published\"})[0]['value']\n",
    "            bip_topics = file_contents.findAll(attrs={\"class\" : \"bip:topics:1.0\"})\n",
    "            if(len(bip_topics) > 0):        \n",
    "                bip_topics = bip_topics[0].findAll(\"code\")  \n",
    "                for val in bip_topics:\n",
    "                    unique_bip_topics.add(val['code'])\n",
    "                code = bip_topics[0]['code']\n",
    "                df = df.append({'Headline': headline, \n",
    "                                   'Text': text, \n",
    "                                   'bip:topics': code,\n",
    "                                   'dc.date.published': dc_date_published, \n",
    "                                   'itemid': itemId,\n",
    "                                   'XMLfilename': fileName\n",
    "                                  }, ignore_index=True)\n",
    "            else:\n",
    "                 df = df.append({'Headline': headline, \n",
    "                                   'Text': text, \n",
    "                                   'bip:topics': \"\",\n",
    "                                   'dc.date.published': dc_date_published, \n",
    "                                   'itemid': itemId,\n",
    "                                   'XMLfilename': fileName\n",
    "                                  }, ignore_index=True)\n",
    "\n",
    "    \n",
    "    return df, unique_bip_topics\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RfFxEDf-16EO"
   },
   "source": [
    "# Question 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YiVcOhML16EQ",
    "outputId": "2a4c4f75-a34a-4143-c8e1-3c41928a0b97"
   },
   "outputs": [],
   "source": [
    "# function to find all the possible values for bip:topics.\n",
    "\n",
    "def getUniqueBipTopics():\n",
    "    # call function to extract xml files and load data frame    \n",
    "    output = loadDataFrame()    \n",
    "    df = output[0]\n",
    "    unique_bip_topics = output[1]\n",
    "    return df, unique_bip_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MCAT', 'CCAT', 'C16', 'C23', 'GPRO', 'G159', 'GWEA', 'E71', 'E11', 'GHEA', 'E143', 'GCAT', 'E51', 'GDIP', 'E411', 'GCRIM', 'C171', 'E511', 'C21', 'E21', 'C32', 'GENV', 'E41', 'E142', 'E512', 'C34', 'C331', 'E61', 'GTOUR', 'C183', 'E311', 'GSPO', 'G15', 'M13', 'M11', 'E131', 'E313', 'GPOL', 'C31', 'GODD', 'GOBIT', 'M142', 'G157', 'C312', 'E12', 'C33', 'GREL', 'GDIS', 'C17', 'GENT', 'C1511', 'G151', 'G155', 'E14', 'GDEF', 'C22', 'C311', 'GVOTE', 'M14', 'C12', 'G156', 'C11', 'GJOB', 'GWELF', 'C313', 'C174', 'C13', 'E121', 'C151', 'C411', 'M141', 'M131', 'C182', 'G153', 'C42', 'ECAT', 'E513', 'C173', 'M132', 'E141', 'G158', 'C41', 'E312', 'E13', 'C172', 'E31', 'GSCI', 'C181', 'E132', 'G152', 'GVIO', 'G154', 'GFAS', 'C18', 'E212', 'M143', 'C15', 'C152', 'C24', 'C14', 'M12', 'E211'}\n"
     ]
    }
   ],
   "source": [
    "#calling function to get all possible bip topics\n",
    "\n",
    "output = getUniqueBipTopics()\n",
    "df = output[0]\n",
    "unique_bip_topics = output[1]\n",
    "print(unique_bip_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n"
     ]
    }
   ],
   "source": [
    "# printing the number of unique bip topics\n",
    "\n",
    "print(len(unique_bip_topics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "11nPi_gx16EU"
   },
   "source": [
    "# Question 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FBb6gywZ16EW"
   },
   "outputs": [],
   "source": [
    "# function to preprocess the text column of dataframe df\n",
    "\n",
    "def textPreprocessing(param_df):\n",
    "    \n",
    "    # removing rows containing null values\n",
    "    param_df = param_df.dropna()\n",
    "\n",
    "    # remove special characters and numbers\n",
    "    param_df.Text = param_df.Text.apply(lambda x: re.sub(r'[^a-z]', ' ', x.lower()))    \n",
    " \n",
    "    #remove everything except nouns\n",
    "    accepted_tags={'NN','NNS','NNP','NNPS'}\n",
    "    param_df.Text = param_df.Text.apply(lambda x: \" \".join([pair[0] for pair in nltk.pos_tag(word_tokenize(x)) if pair[1] in accepted_tags]))\n",
    "      \n",
    "    #remove stop words and lemmatization of words\n",
    "    stopwords_list = set(stopwords.words(\"english\"))\n",
    "    lem = WordNetLemmatizer()\n",
    "    param_df.Text = param_df.Text.apply(lambda x: \" \".join([lem.lemmatize(word) for word in x.split() if word not in stopwords_list]))   \n",
    "    \n",
    "    #removing least common words whose frequency is less than or equal to 5\n",
    "    obj = pd.Series(' '.join(df.Text).split()).value_counts()\n",
    "    wrds = obj[obj<=5]\n",
    "    least_freq = pd.Series(' '.join(df.Text).split()).value_counts()[-len(wrds):]\n",
    "    least_freq = set(least_freq)\n",
    "    df.Text = df.Text.apply(lambda x: \" \".join(word for word in x.split() if word not in least_freq))\n",
    "    \n",
    "    return param_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P3WocQPB16EZ"
   },
   "source": [
    "# Question 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wMbO_VH-16Ea"
   },
   "outputs": [],
   "source": [
    "# function to take the input dataframe and -\n",
    "                  # call the preprocessing method to preprocess the text column of dataframe df \n",
    "                  # extract features from the text \n",
    "                  # and generate a new dataframe of features and labels\n",
    "\n",
    "def extractFeatures(param):\n",
    "    preprocessed_df = textPreprocessing(param)   \n",
    "    \n",
    "    #features\n",
    "    vectorizer = TfidfVectorizer(max_features = 1000)\n",
    "    X_train_counts = vectorizer.fit_transform(preprocessed_df.Text)           \n",
    "\n",
    "    model_df = pd.DataFrame(X_train_counts.toarray(), columns=vectorizer.get_feature_names())\n",
    "\n",
    "    #labels\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    model_df[\"bip:topics:encoded\"] = label_encoder.fit_transform(preprocessed_df['bip:topics'].astype(str))\n",
    "\n",
    "    return model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RWjkQuEu16Ee"
   },
   "source": [
    "# Question 7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reason behind the method using to divide your data into a training and test set:\n",
    "\n",
    "* To validate the performance of the model on unseen data, I have done both sample validation(test-train-split) and K-folds(cross validation with 5 folds) by splitting the entire data which separates the test data and train data. \n",
    "\n",
    "\n",
    "* Cross validation with 5 folds divides my whole data into 5 folds in which one fold is considered as test data and K-1 folds (4 folds) are considered as training data. This whole process is iterated 5 times in which, in each iteration, each fold gets to be taken as test data and remaining K-1 folds as training data. This way I could make sure that my models are not biased to some specific portion of data.\n",
    "\n",
    "\n",
    "* Therefore, I initially checked the performance of model on training data and compare with the performance on unseen data or test data. If the model is performing well on that unseen data as well, there are still chances that the model is biased. To ensure the model is not biased, I performed cross validation with 5-folds in later stage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1DoqzQZc16Ef"
   },
   "outputs": [],
   "source": [
    "#splitting the data into training and testing data\n",
    "\n",
    "def getParameters(new_df):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(new_df.loc[:, new_df.columns != 'bip:topics:encoded'], new_df['bip:topics:encoded'], test_size=0.3, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ti6kJIli16Eh"
   },
   "source": [
    "# Question 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to - \n",
    "#        - extract features from the dataframe, \n",
    "#        - get the required parameters to train a model and \n",
    "#        - return the trained model \n",
    "\n",
    "def getTrainedModel(model):\n",
    "    try:\n",
    "        new_df\n",
    "        \n",
    "    except: #extracting features only first time\n",
    "        new_df = extractFeatures(df)\n",
    "      \n",
    "    finally:\n",
    "    # if features are already extracted        \n",
    "        output = getParameters(new_df)\n",
    "        X_train = output[0]\n",
    "        X_test = output[1]\n",
    "        y_train = output[2]\n",
    "        y_test = output[3]\n",
    "\n",
    "        model_obj = model\n",
    "        trained_model = model_obj.fit(X_train, y_train)\n",
    "        return trained_model, X_test, y_test, new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G6335TI416E6",
    "outputId": "779978d1-1e5e-4d37-ec8f-02150d322fc1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Baye's classifier's Accuracy: 0.7058986047796657\n"
     ]
    }
   ],
   "source": [
    "#Naive Baye's algorithm\n",
    "\n",
    "multinomialNB=MultinomialNB()\n",
    "output = getTrainedModel(multinomialNB)\n",
    "trained_model = output[0]\n",
    "X_test = output[1]\n",
    "y_test = output[2]\n",
    "new_df = output[3]\n",
    "y_pred = trained_model.predict(X_test)\n",
    "print(\"Naive Baye's classifier's Accuracy:\", evaluateClassifier(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WhEwUxNW16E_",
    "outputId": "fd0362a4-d0d0-4236-a18c-7d8748f2f3c1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manju\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score:  0.7057379369196001\n"
     ]
    }
   ],
   "source": [
    "# Evaluation - Cross validation\n",
    "\n",
    "multinomialNB=MultinomialNB()\n",
    "cv_nb = cross_val_score(multinomialNB, new_df.loc[:, new_df.columns != 'bip:topics:encoded'], new_df['bip:topics:encoded'], cv=5)\n",
    "print(\"Cross validation score: \", cv_nb.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UDeT4V3b16Eo"
   },
   "source": [
    "# Question 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the quality of your classifier:\n",
    "\n",
    "* I have chosen Mean Squared Error(MSE) to evaluate the performance of Linear Regression model because in Mean Squared Error, the error will be calculated by taking the average of squares of absolute differences between the target values and the predictions. This is better than Mean Absolute Error (MAE) because it cancels out the negative and positive values and penalizes the errors extremely.\n",
    "\n",
    "* For classification models, I have chosen F1 score to evaluate the performance of classification models - SVM, Decision Tree, Random Forest, and Neural Networks model. F1 score provides the mean of both recall and precision and performs better in evaluating the incorrectly classified cases than the metric accuracy. By taking mean, it gets to penalize these cases at an extreme level. Hence, I chose F1 score since it is better in evaluating False Negative cases compared to other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nms_tJ5O16E0"
   },
   "outputs": [],
   "source": [
    "# function to evaluate the classifier using F1 score\n",
    "\n",
    "def evaluateClassifier(y_test, y_pred):\n",
    "    return f1_score(y_test, y_pred, average = \"micro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z-8cAJIu16E3"
   },
   "source": [
    "# Question 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tRvvBCk516FE",
    "outputId": "f581163d-1858-4b03-86d8-c6ac90f455ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM classifier's Accuracy: 0.7425749412902335\n"
     ]
    }
   ],
   "source": [
    "#SVM algorithm - linear kernel\n",
    "\n",
    "SVM_clf=SVC(kernel='linear')\n",
    "output = getTrainedModel(SVM_clf)\n",
    "trained_model = output[0]\n",
    "X_test = output[1]\n",
    "y_test = output[2]\n",
    "new_df = output[3]\n",
    "y_pred = trained_model.predict(X_test)\n",
    "print(\"SVM classifier's Accuracy:\", evaluateClassifier(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gz4fIHYu16FK",
    "outputId": "efe8121c-673a-4ac3-b0ea-981abd1e6ce0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manju\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=2.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score:  0.7282876782788512\n"
     ]
    }
   ],
   "source": [
    "# Evaluation - Cross validation\n",
    "\n",
    "SVM_clf=SVC(kernel='linear')\n",
    "cv_svm = cross_val_score(SVM_clf, new_df.loc[:, new_df.columns != 'bip:topics:encoded'], new_df['bip:topics:encoded'], cv=5)\n",
    "print(\"Cross validation score: \", cv_svm.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6qJPE4Hy16Ga",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manju\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'C': 10}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search\n",
    "\n",
    "parameter_space = {\n",
    "    'C' : [10, 100, 1000]\n",
    "}\n",
    "svc = SVC(kernel='linear')\n",
    "gs_svc = GridSearchCV(svc, parameter_space, n_jobs=-1, cv=3)\n",
    "gs_svc.fit(X_train, y_train)\n",
    "print('Best parameters found:\\n', gs_svc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7492827496373486\n"
     ]
    }
   ],
   "source": [
    "gs_svc.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tQoUVC8B16FP",
    "outputId": "79da0d22-fef0-4dc3-b9ea-56331977dc26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree classifier's Accuracy: 0.6301936195135396\n"
     ]
    }
   ],
   "source": [
    "# Decision tree classifier\n",
    "\n",
    "dt=DecisionTreeClassifier()\n",
    "output = getTrainedModel(dt)\n",
    "trained_model = output[0]\n",
    "X_test = output[1]\n",
    "y_test = output[2]\n",
    "new_df = output[3]\n",
    "y_pred = trained_model.predict(X_test)\n",
    "print(\"Decision Tree classifier's Accuracy:\", evaluateClassifier(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yg9XePLs16FZ",
    "outputId": "5079d21a-f73d-4a08-84f3-dc9f8b920c69",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manju\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score:  0.6118990136990028\n"
     ]
    }
   ],
   "source": [
    "# Evaluation - Cross validation\n",
    "\n",
    "cv_dt = cross_val_score(dt, new_df.loc[:, new_df.columns != 'bip:topics:encoded'], new_df['bip:topics:encoded'], cv=5)\n",
    "print(\"Cross validation score: \", cv_dt.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9HvKCKMl16GE",
    "outputId": "f937219c-a6ae-4f40-9fde-2fa3adc80270"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manju\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  18 out of  18 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=2,\n",
       "       param_grid={'criterion': ['gini', 'entropy'], 'min_samples_leaf': [1, 2, 4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "\"criterion\":['gini','entropy'],\n",
    "\"min_samples_leaf\" : [1, 2, 4]\n",
    "}\n",
    "# Create a based model\n",
    "rf = DecisionTreeClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 3, n_jobs = 2, verbose = 2)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gzT5PtHG16GG",
    "outputId": "b8ef6e74-242d-4320-b774-0b2e781849f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'min_samples_leaf': 1}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VJ6L06jn16GK",
    "outputId": "1ef8fd3a-1193-442d-95c1-68d5da133ed8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.615970704624653"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7s2vr77p16Fk",
    "outputId": "55dee2c3-536c-45d0-c1f1-d4e1e7008657"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classifier's Accuracy: 0.739268242265555\n"
     ]
    }
   ],
   "source": [
    "# Random Forest classifier\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "output = getTrainedModel(clf)\n",
    "trained_model = output[0]\n",
    "X_test = output[1]\n",
    "y_test = output[2]\n",
    "new_df = output[3]\n",
    "y_pred = trained_model.predict(X_test)\n",
    "print(\"Random Forest classifier's Accuracy:\", evaluateClassifier(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uTR7t52616Fo",
    "outputId": "bc54a596-ed37-4c72-e6c9-5becba3cf9a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manju\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score:  0.7335551261914275\n"
     ]
    }
   ],
   "source": [
    "# Evaluation - Cross validation\n",
    "\n",
    "cv_rf = cross_val_score(clf, new_df.loc[:, new_df.columns != 'bip:topics:encoded'], new_df['bip:topics:encoded'], cv=5)\n",
    "print(\"Cross validation score: \", cv_rf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZrwtbB0016F6",
    "outputId": "2b6b8751-7adf-4223-9444-7d1ee4e65e5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manju\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   6 out of   6 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=2,\n",
       "       param_grid={'n_estimators': [70, 150], 'random_state': [42]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators':[70, 150],\n",
    "    'random_state':[42]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = 2, verbose = 2)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fKmkmN8I16F9",
    "outputId": "d17582fd-3504-42cb-9d90-9ee35fd5d096"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 150, 'random_state': 42}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4_dxfMLi16F_",
    "outputId": "dfe420ef-537b-41fc-e0e5-6a3a348375fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7340086232354852"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "32DYVhvz16Fr",
    "outputId": "3f44f830-5e7d-4846-bcfb-3cef46814d39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural networks classifier's Accuracy: 0.4446056085094626\n"
     ]
    }
   ],
   "source": [
    "# Neural Networks - MLP classifier\n",
    "\n",
    "Mlp_clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "output = getTrainedModel(Mlp_clf)\n",
    "trained_model = output[0]\n",
    "X_test = output[1]\n",
    "y_test = output[2]\n",
    "new_df = output[3]\n",
    "y_pred = trained_model.predict(X_test)\n",
    "print(\"Neural networks classifier's Accuracy:\", evaluateClassifier(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Networks - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Npvm0HtD16Fu",
    "outputId": "aa791a5f-ad50-47a5-f93e-f71622ebcf46"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manju\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score:  0.4486571870075339\n"
     ]
    }
   ],
   "source": [
    "# Evaluation - Cross validation\n",
    "\n",
    "cv_nn = cross_val_score(Mlp_clf, new_df.loc[:, new_df.columns != 'bip:topics:encoded'], new_df['bip:topics:encoded'], cv=5)\n",
    "print(\"Cross validation score: \", cv_nn.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Networks - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "PX6T1fTn16GP",
    "outputId": "7b16cf29-fdc9-46bc-9159-accf30eef0fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manju\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'alpha': 0.2, 'hidden_layer_sizes': 9, 'solver': 'adam'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manju\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "parameter_space = {\n",
    "    'hidden_layer_sizes': np.arange(5, 10),\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [0.2]\n",
    "}\n",
    "mlp = MLPClassifier()\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
    "clf.fit(X_train, y_train)\n",
    "print('Best parameters found:\\n', clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "k0d_044l16GR",
    "outputId": "7350c89a-a574-4361-ccd5-1e80c5495ae6",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7312531454453951"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ur2UNhwU16Fy",
    "outputId": "057f8020-3871-4b63-c230-c89cca68b9a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regressor's Mean Squared Error: 188.4527022608793\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression algorithm\n",
    "\n",
    "regressor = LinearRegression()  \n",
    "output = getTrainedModel(regressor)\n",
    "trained_model = output[0]\n",
    "X_test = output[1]\n",
    "y_test = output[2]\n",
    "new_df = output[3]\n",
    "y_pred = trained_model.predict(X_test)\n",
    "print(\"Linear Regressor's Mean Squared Error:\", metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression - cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score:  0.6802368053742873\n"
     ]
    }
   ],
   "source": [
    "# Evaluation - Cross validation\n",
    "\n",
    "cv_lr = cross_val_score(regressor, new_df.loc[:, new_df.columns != 'bip:topics:encoded'], new_df['bip:topics:encoded'], cv=5)\n",
    "print(\"Cross validation score: \", cv_lr.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ChV3Ux7N16GV",
    "outputId": "e4da9dae-b394-4291-8100-a3fcae459986"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'copy_X': True, 'fit_intercept': True, 'normalize': True}\n"
     ]
    }
   ],
   "source": [
    "parameter_space = {\n",
    "    'normalize':[True,False],\n",
    "    'copy_X':[True,False],\n",
    "    'fit_intercept':[True,False]\n",
    "}\n",
    "lr = LinearRegression()\n",
    "gs_lr = GridSearchCV(lr, parameter_space, n_jobs=-1, cv=3)\n",
    "gs_lr.fit(X_train, y_train)\n",
    "print('Best parameters found:\\n', gs_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "eE5v_7mz16GX",
    "outputId": "c7c57b3a-a2e2-428c-e07d-259533bac853",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6829329411677455"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Classifier - SVM:\n",
    "\n",
    "Among all the five models - Linear Regression, SVM, Decision Trees, Random Forest and Neural Networks, SVM with linear kernel is found to be a best classifier.\n",
    "\n",
    "* <b> Before Grid Search </b> :\n",
    "    Initially, using the train-test-split method, an F1 score of 0.742 is resulted, whereas with the cross validation method, cross validation score is found to be 0.728. I tried to improve the results using Hyper Parameter Tuning technique. \n",
    "\n",
    "* <b> After Grid Search: </b>\n",
    "    I have used the Grid Search technique to help me find the optimal values for hyper parameters that provides best accurate results. With this approach, I tried with various values of C which is the penalty parameter of the error term. The best_params_ attribute of Grid search showed the best hyper parameters that suggests the values for parameter C and the attribute \"best_score_\" of the grid search provided the mean cross-validated score. Here, I got the cross validated score of 0.749 which clearly showed a minor improvement of 2% compared to the performance of SVM Classifier before Grid Search (0.728). \n",
    "\n",
    "Moreover, since SVM with linear kernel performs better in most of the text classification problems especially when the data distribution is imbalanced, considering the performance of it on our data, I would choose SVM is the best classifier irrespective of the model training time. \n",
    "\n",
    "However, if training times are to be considered and more number of features are to be included in future to train the model on, Random Forest classifier will also be a good choice since its training times are comparitively faster than SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[1] Python, A. (2019). A Comprehensive Guide to Understand and Implement Text Classification in Python. [online] Analytics Vidhya. Available at: https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/ [Accessed 24 Oct. 2019].\n",
    "\n",
    "[2] Hintermeier, A. and Buffalo, N. (2019). Feature Extraction from Text. [online] Home. Available at: https://andhint.github.io/machine-learning/nlp/Feature-Extraction-From-Text/ [Accessed 24 Oct. 2019].\n",
    "\n",
    "[3] K. N. K. Nguyen, “Pandas How to filter a Series,” Stack Overflow, 01-May-1965. [Online]. Available: https://stackoverflow.com/questions/28272137/pandas-how-to-filter-a-series. [Accessed: 24-Oct-2019].\n",
    "\n",
    "[4] A. Verma, “Feature Extraction from Text (text data preprocessing),” Medium, 06-Jun-2019. [Online]. Available: https://medium.com/100-days-of-ml-and-code/feature-extraction-from-text-text-data-preprocessing-594b11af19f5. [Accessed: 24-Oct-2019].\n",
    "\n",
    "[5] “5.2. Feature extraction¶,” scikit. [Online]. Available: https://scikit-learn.org/stable/modules/feature_extraction.html. [Accessed: 24-Oct-2019].\n",
    "\n",
    "[6] user1599325, user1599325user1599325 1711 gold badge22 silver badges99 bronze badges, and MerlinMerlin 10.2k3030 gold badges8686 silver badges166166 bronze badges, “IOPub data rate exceeded in Jupyter notebook (Version 5.4.0),” Stack Overflow, 01-Nov-1968. [Online]. Available: https://stackoverflow.com/questions/51697516/iopub-data-rate-exceeded-in-jupyter-notebook-version-5-4-0. [Accessed: 24-Oct-2019].\n",
    "\n",
    "[7] freeCodeCamp.org, “How to extract keywords from text with TF-IDF and Python's Scikit-Learn,” freeCodeCamp.org, 28-Feb-2019. [Online]. Available: https://www.freecodecamp.org/news/how-to-extract-keywords-from-text-with-tf-idf-and-pythons-scikit-learn-b2a0f3d7e667/. [Accessed: 24-Oct-2019].\n",
    "\n",
    "[8] “Text Analytics for Beginners using NLTK,” DataCamp Community. [Online]. Available: https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk. [Accessed: 24-Oct-2019].\n",
    "\n",
    "[9] “Stemming and Lemmatization in Python,” DataCamp Community. [Online]. Available: https://www.datacamp.com/community/tutorials/stemming-lemmatization-python#targetText=Stemming and Lemmatization both generate,words which makes it faster. [Accessed: 24-Oct-2019]."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment_B00825788 - v3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
